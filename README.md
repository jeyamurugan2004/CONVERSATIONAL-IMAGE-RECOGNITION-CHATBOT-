# CONVERSATIONAL-IMAGE-RECOGNITION-CHATBOT-
Final Year Main Project
A Vision language model has been developed to automate the generation clinical captions for chest X-ray images and explained detailly using Large Language model . Traditional radiological workflows depends on manual interpretation, which is slow, subjective, and resource-intensive and also when it handling large volumes of imaging data. Conventional methods are also struggling to capture the nuanced association between visual pattern and clinical terminology which limits their effectiveness in automated diagnosis. To address these limitations, a fine-tuned vision-language architecture based on LLaMA 3.2 Vision which stands for Large Language Model Meta AI was implemented using Low-Rank Adaptation (LoRA) and 4-bit quantization techniques. The Unsloth library was used to enable efficient model training using limited hardware. The ROCOv2 dataset which stands for Radiology Objects in Context , consists of chest X-ray images paired with medical captions, has been used as the primary data source, enabling the model to learn clinically relevant visual-text embeddings . The training pipeline which is involves in the semantic alignment of image features in chest x rays and its respective textual data of scan report for the task such as image captioning and visual question answering. 
Problem Identification - Radiology is crucial for diagnosing conditions related to the lungs and the thorax. Chest X-rays are particularly important as they are one of the most cost-effective and easily obtainable imaging tests. 
